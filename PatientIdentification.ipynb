{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e51f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms,models,utils\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b20c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train\"\n",
    "test_path = \"test\"\n",
    "data_root = \"train\"\n",
    "csv_path = \"result\"\n",
    "tensorboard_path = \"../tensorboard\"\n",
    "model_save_path = \"../model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ddaef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path:str, train=True, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.train_flag = train\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(224, 224)),\n",
    "                transforms.Grayscale(num_output_channels=3),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        \n",
    "        # 遍历文件夹并将文件名列表存储在 self.path_list 中\n",
    "        self.path_list = []\n",
    "        for root, _, files in os.walk(data_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.tif'):\n",
    "                    self.path_list.append(os.path.join(root, file))\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = self.path_list[idx]\n",
    "        name = \"\"\n",
    "        \n",
    "        if self.train_flag is True:\n",
    "            if 'Patient' in img_path:  # 修改标签的计算方式\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "        else:\n",
    "            label = int(os.path.basename(img_path).split('#')[1])\n",
    "            name = os.path.basename(img_path).split('.')[0]\n",
    "        \n",
    "        label = torch.as_tensor(label, dtype=torch.int64)\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img, label, name\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d80d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.2471, -0.1765, -0.0667,  ...,  0.0902,  0.0353,  0.0353],\n",
      "         [ 0.2471,  0.3490,  0.4902,  ...,  0.7098,  0.6078,  0.6000],\n",
      "         [ 0.4039,  0.4667,  0.5451,  ...,  0.6784,  0.5843,  0.5451],\n",
      "         ...,\n",
      "         [-0.6000, -0.6627, -0.7020,  ..., -0.6706, -0.6549, -0.6549],\n",
      "         [-0.7255, -0.7490, -0.8039,  ..., -0.8196, -0.7804, -0.7490],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-0.2471, -0.1765, -0.0667,  ...,  0.0902,  0.0353,  0.0353],\n",
      "         [ 0.2471,  0.3490,  0.4902,  ...,  0.7098,  0.6078,  0.6000],\n",
      "         [ 0.4039,  0.4667,  0.5451,  ...,  0.6784,  0.5843,  0.5451],\n",
      "         ...,\n",
      "         [-0.6000, -0.6627, -0.7020,  ..., -0.6706, -0.6549, -0.6549],\n",
      "         [-0.7255, -0.7490, -0.8039,  ..., -0.8196, -0.7804, -0.7490],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-0.2471, -0.1765, -0.0667,  ...,  0.0902,  0.0353,  0.0353],\n",
      "         [ 0.2471,  0.3490,  0.4902,  ...,  0.7098,  0.6078,  0.6000],\n",
      "         [ 0.4039,  0.4667,  0.5451,  ...,  0.6784,  0.5843,  0.5451],\n",
      "         ...,\n",
      "         [-0.6000, -0.6627, -0.7020,  ..., -0.6706, -0.6549, -0.6549],\n",
      "         [-0.7255, -0.7490, -0.8039,  ..., -0.8196, -0.7804, -0.7490],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]), tensor(0), '')\n"
     ]
    }
   ],
   "source": [
    "train_ds = MyDataset(train_path)\n",
    "test_ds = MyDataset(test_path,train=False)\n",
    "for i, item in enumerate(train_ds):\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd55e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = train_ds\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "validate_size = len(full_ds) - train_size\n",
    "new_train_ds, validate_ds = torch.utils.data.random_split(full_ds,[train_size, validate_size]) #数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a93533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "new_train_loader = torch.utils.data.DataLoader(new_train_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_ds, batch_size=32,\n",
    "                                            shuffle=True, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85c48294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(train_loader):\n",
    "#     pass\n",
    "    print(item[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22ad06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_PIL_Tensor = train_ds[1][0]\n",
    "# new_img_PIL = transforms.ToPILImage()(img_PIL_Tensor).convert('RGB')\n",
    "# plt.imshow(new_img_PIL)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f354b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,8,kernel_size=3,stride=1,padding=1) # 按照公式计算后经过卷积层不改变尺寸\n",
    "        self.pool = nn.MaxPool2d(2,2) # 2*2的池化 池化后size 减半\n",
    "        self.conv2 = nn.Conv2d(8,16,kernel_size=3,stride=1,padding=1)\n",
    "        self.fc1 = nn.Linear(16*56*56,256)#两个池化，所以是224/2/2=56\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64,2)\n",
    "#         self.dp = nn.Dropout(p=0.5)\n",
    "    def forward(self,x):\n",
    "#         print(\"input:\", x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "#         print(\"first conv:\", x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print(\"second conv:\", x)\n",
    "\n",
    "        x = x.view(-1, 16 * 56* 56)#将数据平整为一维的 \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))  \n",
    "        x = self.fc3(x)  \n",
    "#         x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebf575f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tony\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=False)  \n",
    "model_path = 'E:/BMU/Identify-master/PyTorch/resnet50-19c8e357.pth'\n",
    "resnet50.load_state_dict(torch.load(model_path))\n",
    "resnet50.fc = nn.Linear(2048, 2) #修改最后一层网络将输出调整为两维\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c2d538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "569f2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk) \n",
    "    batch_size = label.size(0)\n",
    "\n",
    "    # 获取前K的索引\n",
    "    _, pred = output.topk(maxk, 1, True, True) #使用topk来获得前k个的索引\n",
    "    pred = pred.t() # 进行转置\n",
    "    # eq按照对应元素进行比较 view(1,-1) 自动转换到行为1,的形状， expand_as(pred) 扩展到pred的shape\n",
    "    # expand_as 执行按行复制来扩展，要保证列相等\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred)) # 与正确标签序列形成的矩阵相比，生成True/False矩阵\n",
    "#     print(correct)\n",
    "\n",
    "    rtn = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0) # 前k行的数据 然后平整到1维度，来计算true的总个数\n",
    "        rtn.append(correct_k.mul_(100.0 / batch_size)) # mul_() ternsor 的乘法  正确的数目/总的数目 乘以100 变成百分比\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f406af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "writer = SummaryWriter('./tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f21aaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epochs, train_loader, device, model, criterion, optimizer,tensorboard_path):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        train_loader = tqdm(train_loader)\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        top1 = AvgrageMeter()\n",
    "        train_loader.set_description('[%s%04d/%04d %s%f]' % ('Epoch:', epoch + 1, epochs, 'lr:', 0.001))\n",
    "        for i, data in enumerate(train_loader, 0):  # 0是下标起始位置默认为0\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # 初始为0，清除上个batch的梯度信息\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #topk准确率\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            n = inputs.size(0)\n",
    "            top1.update(prec1.item(), n)\n",
    "            train_loss += loss.item()\n",
    "            postfix = {'train_loss': '%.6f' % (train_loss / (i + 1)), 'train_acc': '%.6f' % top1.avg}\n",
    "            train_loader.set_postfix(log=postfix)\n",
    "\n",
    "            # ternsorboard 曲线绘制\n",
    "            writer = SummaryWriter(tensorboard_path)\n",
    "            writer.add_scalar('Train/Loss', loss.item(), epoch)\n",
    "            writer.add_scalar('Train/Accuracy', top1.avg, epoch)\n",
    "            writer.flush()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29448ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(validate_loader, device, model, criterion):\n",
    "    val_acc = 0.0\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # 进行评测的时候网络不更新梯度\n",
    "        val_top1 = AvgrageMeter()\n",
    "        validate_loader = tqdm(validate_loader)\n",
    "        validate_loss = 0.0\n",
    "        for i, data in enumerate(validate_loader, 0):  # 0是下标起始位置默认为0\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #         inputs,labels = data[0],data[1]\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            prec1, prec2 = accuracy(outputs, labels, topk=(1, 2))\n",
    "            n = inputs.size(0)\n",
    "            val_top1.update(prec1.item(), n)\n",
    "            validate_loss += loss.item()\n",
    "            postfix = {'validate_loss': '%.6f' % (validate_loss / (i + 1)), 'validate_acc': '%.6f' % val_top1.avg}\n",
    "            validate_loader.set_postfix(log=postfix)\n",
    "        val_acc = val_top1.avg\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb57df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(csv_path,test_loader, device, model):\n",
    "    result_list = []\n",
    "    model = model.to(device)\n",
    "    test_loader = tqdm(test_loader)\n",
    "    with torch.no_grad():  # 进行评测的时候网络不更新梯度\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            softmax_func = nn.Softmax(dim=1)  # dim=1表示行的和为1\n",
    "            soft_output = softmax_func(outputs)\n",
    "            predicted = soft_output[:, 1]\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i].item() <= 0.5:\n",
    "                    res = \"unhealthy\"\n",
    "                else:\n",
    "                    res = \"healthy\"\n",
    "                result_list.append({\n",
    "                    \"id\": labels[i].item(),\n",
    "                    \"label\": predicted[i].item(),\n",
    "                    \"result\": res  # Add the new \"name\" column\n",
    "                })\n",
    "    # 从list转成 dataframe 然后保存为csv文件\n",
    "    columns = result_list[0].keys()\n",
    "    result_dict = {col: [anno[col] for anno in result_list] for col in columns}\n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "    result_df = result_df.sort_values(\"id\")\n",
    "    result_df.to_csv(csv_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52541e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyCNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCELoss()  #二分类交叉熵损失函数\n",
    "# criterion = nn.BCEWithLogitsLoss() #二分类交叉熵损失函数 带log loss\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#也可以选择Adam优化方法\n",
    "# optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f761f55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62360352c82a49c6b5d212726c81f53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00a6d74b196415ab8318bc2ba0ce985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bfa3e1369c40b1966b56e8d23ef9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train( 3, new_train_loader, device,net, criterion, optimizer,tensorboard_path) # 划分80%后的训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02527c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(net.state_dict(), model_save_path)\n",
    "val_net = MyCNN()\n",
    "val_net.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "955a87c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdc65396d4a48609d72dab198be0b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "98.67635608616662"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(validate_loader,device,val_net,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e4f089e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea4e166fcf74586a0995d482ccb32e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission('./test.csv',test_loader, device, val_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae5a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
